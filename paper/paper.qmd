---
title: "Forecasting the 2024 U.S. Presidential Election: A Poll-of-Polls Approach for Predicting the Outcome"
subtitle: "Applying Aggregated Poll Data and Statistical Model to Reveal a Narrow Path to Victory in a Highly Competitive Race"
author: 
  - Chendong Fei
  - Xinze Wu
  - Claire Ma
thanks: "Code and data are available at: https://github.com/ke3w/Prediction_US_presidential_election.git"
date: today
date-format: long
abstract: "This paper develops a model to forecast the outcome of the 2024 U.S. presidential election by analyzing aggregated polling data, or “poll-of-polls,” sourced from FiveThirtyEight. Using a generalized linear model, we assess national trends alongside key battleground state polls to predict each candidate's likelihood of victory. The findings indicate a closely contested race, with specific demographic and regional factors creating narrow pathways to winning the presidency. This analysis highlights the value of aggregated polling data in understanding electoral dynamics and demonstrates the importance of statistical modeling in making informed predictions about major political events."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(ggplot2)
library(MASS)
library(dplyr)
```

# Introduction

The outcome of the U.S. presidential election has far-reaching implications, shaping both domestic policies and international relations. As the 2024 election approaches, voters and analysts turn to polls to understand the state of the race between Vice President Kamala Harris, the Democratic candidate, and former President Donald Trump, the Republican candidate. However, individual polls are often limited by their methodologies, timing, and sample demographics, leading to variations in predictions. To overcome these limitations, aggregating multiple polls—a technique known as “poll-of-polls”—provides a more stable and reliable indicator of public opinion. This paper applies a poll-of-polls approach, informed by methodologies from individual polls[@blumenthal2014; @pasek2015], to predict the outcome of the 2024 U.S. presidential election, focusing on data aggregated by FiveThirtyEight[@fivethirtyeight2024].

The primary objective of this analysis is to forecast which candidate is likely to win the 2024 election based on aggregated national and battleground state polling data. By constructing a generalized linear model, we aim to distill insights from the extensive polling data available, examining trends and key demographic indicators.

The primary estimand in this analysis is the probability of each candidate winning the 2024 U.S. presidential election based on aggregated polling data. This probability is derived from a weighted average of poll results across national and battleground states, with adjustments for factors such as recent polling trends, sample sizes, and state-specific electoral significance.

Our analysis reveals a highly competitive race, with key battleground states playing a pivotal role in determining the overall outcome. The model identifies specific regions and demographics that are likely to influence the election results, highlighting the polarized nature of the electorate.As of November 1, 2024, FiveThirtyEight’s national polling average indicates a slight edge for Harris, who has 48.1% support compared to Trump’s 46.7%. Despite this narrow national lead, the race in critical battleground states remains highly competitive. For instance, Pennsylvania is evenly split, with Harris holding marginal leads in states like Wisconsin and Michigan, while Trump shows slight advantages in Nevada, Georgia, and Arizona. These tight margins highlight the crucial role battleground states play in determining the election’s outcome.

These findings underscore the importance of aggregated poll data in capturing the broader political landscape, offering insights that single polls may miss. By understanding the dynamics at play, this study contributes to a broader understanding of electoral processes and the predictive power of statistical models in forecasting complex political events.

This paper is organized as follows: @sec-data discusses the details of the dataset. @sec-Methodology describes the methodology, including generalized linear model. @sec-Results presents the results, highlighting trends in polling, and @sec-Discussion considers the implications of these results for future research on polling and public opinion.

# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR] to analyze polling data from FiveThirtyEight’s U.S. Presidential election polls [@fivethirtyeight2024]. The dataset contains information such as pollster, polling date, methodology, sample size, state, and candidate support percentages. It allows us to track voter sentiment across different regions and polling methods, providing a comprehensive view of the election landscape. Additionally, irrelevant or incomplete entries were removed to ensure clean, high-quality data, and we retained only key variables to streamline the analysis. This careful selection and cleaning process ensure that the dataset offers a precise and representative snapshot of the election landscape.

## Measurement

The dataset measures public opinion on the 2024 U.S. presidential election by aggregating polling data to estimate voter support for each candidate at both national and state levels. These polling data entries are then aggregated, which applies a weighted adjustment to reflect the reliability, sample size, and recency of each poll. This weighting process addresses the natural variation in polling methodologies (e.g., online survey, phone), sample diversity, and timing, which influence the reliability of each poll as a measure of the broader population’s preferences.For instance, if this poll was conducted a week before the election, it might be weighted more heavily than a poll from three months prior, as it better represents current voter sentiment. By weighting higher-quality and more recent polls more heavily, it creates a comprehensive measure that accounts for both regional and national voter sentiment, smoothing out biases from individual polls.

## Outcome variables

In our analysis, the primary outcome variable is labeled `win`, which is a binary indicator representing the likelihood of a candidate "winning" in each poll based on their support percentage. Specifically, `win` is defined as follows: if a candidate's support percentage (`pct`) in a given poll exceeds 50%, then `win` is assigned a value of 1, indicating a projected win for that candidate in that poll. If the support percentage is 50% or below, `win` is assigned a value of 0, indicating that the candidate is not the likely winner in that poll. This binary outcome variable is particularly useful for logistic regression analysis, as it allows us to model the probability of a candidate achieving majority support in each poll. Using win provides a clear and interpretable framework to assess factors influencing a candidate’s chances of gaining majority support, which aligns well with election forecasting goals. Additionally, this threshold reflects the electoral concept of a "win," as it represents the point at which a candidate has more than half of the vote share, an essential consideration in political analysis.

## Predictor variables

The predictor variables in this analysis were chosen based on their potential influence on polling outcomes and candidate support. Each predictor reflects characteristics of the poll, the pollster, or the candidate's support environment. These variables aim to capture the factors that could impact the likelihood of a candidate reaching majority support (win = 1). Key predictor variables include:

-   **sample_size**: Represents the number of respondents in each poll, with larger sample sizes generally leading to more reliable results.
-   **pollster Rating**: Indicates the quality and historical accuracy of the polling organization, helping to account for differences in poll reliability.
-   **state**: Captures the geographical region of the poll, reflecting regional differences in voter support that are crucial in U.S. elections.

These three variables provide a balanced view of poll quality, reliability, and regional influence, enhancing the model's ability to predict election outcomes accurately. This combination ensures that the model is interpretable and captures essential factors influencing voter sentiment. We apply Bayesian Information Criterion (BIC) method to select significant predictors, and a summary statistics for this method shown in @Appendix

```{r}
# Define the binary response variable if not already defined
# Create a binary `win` variable where pct > 50% indicates a "win"
data <- data %>%
  mutate(win = ifelse(pct > 50, 1, 0))
# Fit the full logistic regression model with all predictors
full_model <- glm(
  win ~ sample_size + pollscore + transparency_score + 
          methodology + start_date + end_date + state + party, 
  data = data, 
  family = binomial
)
# Use stepwise selection based on BIC
best_model <- stepAIC(
  full_model, 
  direction = "both", 
  k = log(nrow(data)) # Set k to log(n) for BIC
)

# Display the summary of the selected model based on BIC
summary(best_model)
# View final model formula and BIC value
formula(best_model)
BIC(best_model)
```

#model

# Model Analysis

In this study, we employed a Generalized Linear Model (GLM) to forecast the winner of the upcoming US presidential election. The model uses polling data to estimate the probability of each candidate winning a given state, enabling us to predict the overall election result. We used a logistic regression approach, where the outcome is a binary variable (1 if the candidate wins, 0 otherwise).

## Model Set-Up

The model takes the following form:

$$
P(y_i = 1) = \text{logit}^{-1}(\alpha + \beta_1 \cdot \text{pollscore}_i + \beta_2 \cdot \text{log\_sample\_size}_i + \gamma_{\text{state}_i} + \delta_{\text{pollster\_rating}_i})
$$

where (y_i) represents the probability of candidate (i) winning, ( \alpha ) is the intercept, and the coefficients (( \beta, \gamma, \delta )) represent the effects of predictors like poll score, sample size, state, and pollster rating.

The model was trained using polling data, aggregated from multiple sources (the poll-of-polls approach), which helped to minimize biases associated with individual polls. The logistic link function was employed to model the binary outcome of winning or losing in each state.

## Election Probability Estimation and Winner Prediction

The GLM provides a probability estimate for each candidate in every state. We applied a threshold of 0.5 to classify a candidate as the winner for each state. By aggregating the predicted winners across all states, we determined the overall forecast for the election.

The model results suggest that Candidate A has a predicted win in several key battleground states, giving them an estimated advantage in the electoral college. Based on these state-level predictions, Candidate A is forecasted to win the upcoming US presidential election.

## Model Diagnostics

We performed several diagnostic evaluations to ensure the reliability of our model:

-   **Residual Analysis**: Examined residual vs. fitted plots to assess any systematic patterns.
-   **Normal Q-Q Plot**: Used to verify that the residuals follow a normal distribution.
-   **Cook's Distance**: Identified potential influential observations that could have a disproportionate effect on the model.

These diagnostics indicated that the model performed well, with no significant violations of assumptions that would undermine the predictions.

## Model Results and Visualizations

The model coefficients and summary statistics are presented in Table @tbl-modelresults. These results provide insights into how different factors—such as poll quality and sample size—affect the probability of winning.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

# Load the election model
election_model <- readRDS(file = here::here("models/election_model.rds"))
```
```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Model results for predicting the winner of the election"
#| warning: false

modelsummary::modelsummary(
  list(
    "Election Model" = election_model
  ),
  statistic = "mad",
  fmt = 2
)
```


# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this.

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {.unnumbered}

# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows...

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```

\newpage

# References
