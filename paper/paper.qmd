---
title: "Forecasting the 2024 U.S. Presidential Election: A Poll-of-Polls Approach for Predicting the Outcome"
subtitle: "Applying Aggregated Poll Data and Statistical Model to Reveal a Narrow Path to Victory in a Highly Competitive Race"
author: 
  - Chendong Fei
  - Xinze Wu
  - Claire Ma
thanks: "Code and data are available at: https://github.com/ke3w/Prediction_US_presidential_election.git"
date: today
date-format: long
abstract: "This paper develops a model to forecast the outcome of the 2024 U.S. presidential election by analyzing aggregated polling data, or “poll-of-polls,” sourced from FiveThirtyEight. Using a generalized linear model, we assess national trends alongside key battleground state polls to predict each candidate's likelihood of victory. The findings indicate a closely contested race, with specific demographic and regional factors creating narrow pathways to winning the presidency. This analysis highlights the value of aggregated polling data in understanding electoral dynamics and demonstrates the importance of statistical modeling in making informed predictions about major political events."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(ggplot2)
library(MASS)
library(dplyr)
library(rstanarm)

```

# Introduction

The outcome of the U.S. presidential election has far-reaching implications, shaping both domestic policies and international relations. As the 2024 election approaches, voters and analysts turn to polls to understand the state of the race between Vice President Kamala Harris, the Democratic candidate, and former President Donald Trump, the Republican candidate. However, individual polls are often limited by their methodologies, timing, and sample demographics, leading to variations in predictions. To overcome these limitations, aggregating multiple polls—a technique known as “poll-of-polls”—provides a more stable and reliable indicator of public opinion. This paper applies a poll-of-polls approach, informed by methodologies from individual polls[@blumenthal2014; @pasek2015], to predict the outcome of the 2024 U.S. presidential election, focusing on data aggregated by FiveThirtyEight[@fivethirtyeight2024].

The primary objective of this analysis is to forecast which candidate is likely to win the 2024 election based on aggregated national and battleground state polling data. By constructing a generalized linear model, we aim to distill insights from the extensive polling data available, examining trends and key demographic indicators.

The primary estimand in this analysis is the probability of each candidate winning the 2024 U.S. presidential election based on aggregated polling data. This probability is derived from a weighted average of poll results across national and battleground states, with adjustments for factors such as recent polling trends, sample sizes, and state-specific electoral significance.

Our analysis reveals a highly competitive race, with key battleground states playing a pivotal role in determining the overall outcome. The model identifies specific regions and demographics that are likely to influence the election results, highlighting the polarized nature of the electorate.As of November 1, 2024, FiveThirtyEight’s national polling average indicates a slight edge for Harris, who has 48.1% support compared to Trump’s 46.7%. Despite this narrow national lead, the race in critical battleground states remains highly competitive. For instance, Pennsylvania is evenly split, with Harris holding marginal leads in states like Wisconsin and Michigan, while Trump shows slight advantages in Nevada, Georgia, and Arizona. These tight margins highlight the crucial role battleground states play in determining the election’s outcome.

These findings underscore the importance of aggregated poll data in capturing the broader political landscape, offering insights that single polls may miss. By understanding the dynamics at play, this study contributes to a broader understanding of electoral processes and the predictive power of statistical models in forecasting complex political events.

This paper is organized as follows: @sec-data discusses the details of the dataset. @sec-Methodology describes the methodology, including generalized linear model. @sec-Results presents the results, highlighting trends in polling, and @sec-Discussion considers the implications of these results for future research on polling and public opinion.

# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR] to analyze polling data from FiveThirtyEight’s U.S. Presidential election polls [@fivethirtyeight2024]. The dataset contains information such as pollster, polling date, methodology, sample size, state, and candidate support percentages. It allows us to track voter sentiment across different regions and polling methods, providing a comprehensive view of the election landscape. Additionally, irrelevant or incomplete entries were removed to ensure clean, high-quality data, and we retained only key variables to streamline the analysis. This careful selection and cleaning process ensure that the dataset offers a precise and representative snapshot of the election landscape.

## Measurement

The dataset measures public opinion on the 2024 U.S. presidential election by aggregating polling data to estimate voter support for each candidate at both national and state levels. These polling data entries are then aggregated, which applies a weighted adjustment to reflect the reliability, sample size, and recency of each poll. This weighting process addresses the natural variation in polling methodologies (e.g., online survey, phone), sample diversity, and timing, which influence the reliability of each poll as a measure of the broader population’s preferences.For instance, if this poll was conducted a week before the election, it might be weighted more heavily than a poll from three months prior, as it better represents current voter sentiment. By weighting higher-quality and more recent polls more heavily, it creates a comprehensive measure that accounts for both regional and national voter sentiment, smoothing out biases from individual polls.

## Outcome variables

In our analysis, the primary outcome variable is labeled `win`, which is a binary indicator representing the likelihood of a candidate "winning" in each poll based on their support percentage. Specifically, `win` is defined as follows: if a candidate's support percentage (`pct`) in a given poll exceeds 50%, then `win` is assigned a value of 1, indicating a projected win for that candidate in that poll. If the support percentage is 50% or below, `win` is assigned a value of 0, indicating that the candidate is not the likely winner in that poll. This binary outcome variable is particularly useful for logistic regression analysis, as it allows us to model the probability of a candidate achieving majority support in each poll. Using win provides a clear and interpretable framework to assess factors influencing a candidate’s chances of gaining majority support, which aligns well with election forecasting goals. Additionally, this threshold reflects the electoral concept of a "win," as it represents the point at which a candidate has more than half of the vote share, an essential consideration in political analysis.

## Predictor variables

The predictor variables in this analysis were chosen based on their potential influence on polling outcomes and candidate support. Each predictor reflects characteristics of the poll, the pollster, or the candidate's support environment. These variables aim to capture the factors that could impact the likelihood of a candidate reaching majority support (win = 1). Key predictor variables include:

-   **sample_size**: Represents the number of respondents in each poll, with larger sample sizes generally leading to more reliable results.
-   **pollster Rating**: Indicates the quality and historical accuracy of the polling organization, helping to account for differences in poll reliability.
-   **state**: Captures the geographical region of the poll, reflecting regional differences in voter support that are crucial in U.S. elections.

These three variables provide a balanced view of poll quality, reliability, and regional influence, enhancing the model's ability to predict election outcomes accurately. This combination ensures that the model is interpretable and captures essential factors influencing voter sentiment. We apply Bayesian Information Criterion (BIC) method to select significant predictors, and a summary statistics for this method shown in @Appendix

# Model

```{r}
#| echo: false
#| include: false
# Load libraries and data
library(tidyverse)
library(ggplot2)
library(rstanarm)
library(arrow)

clean_president_polls <- read_parquet("../data/02-analysis_data/cleaned_president_polls.parquet")

clean_president_polls <- clean_president_polls %>%
  mutate(
    weight = numeric_grade * (sample_size / mean(sample_size)),
    pollster = as.factor(pollster),
    state = as.factor(state),
    candidate_label = ifelse(is_harris == 1, "Harris", "Trump")
  )

```

## Description of the Model

The model used for this analysis is a Bayesian generalized linear mixed model (GLMM) with a logistic regression link function. This model was designed to predict the probability of Kamala Harris winning an election based on polling data. Several key predictors are incorporated into the model, including the poll percentage, polling organization, and state-level variability. The specific formula used in the model is:

where:

-   represents the outcome that Kamala Harris wins the poll.

-   "pct" is the percentage of support that Harris received in the poll.

-   "pollster" represents the polling organization, modeled as a random effect to account for differences in reliability or bias between pollsters.

-   "state" represents the U.S. state where the polling data was collected, also modeled as a random effect to capture variability between states.

The model captures both the fixed effect of poll percentage () and the random effects attributable to differences between pollsters and states.

```{r}
#| echo: false
# Fit Bayesian model
bayesian_model <- stan_glmer(
  is_harris ~ pct + (1 | pollster) + (1 | state),
  data = clean_president_polls,
  family = binomial(link = "logit"),
  prior = normal(0.5, 0.1, autoscale = TRUE),
  prior_intercept = normal(0.5, 0.1, autoscale = TRUE),
  weights = weight,
  cores = 4,
  adapt_delta = 0.95,
  refresh = 0
)

# Predict probabilities
clean_president_polls <- clean_president_polls %>%
  mutate(
    predicted_prob_harris = posterior_predict(bayesian_model, newdata = clean_president_polls, type = "response") %>% colMeans(),
    winner_harris = ifelse(predicted_prob_harris > 0.5, 1, 0)
  )

# Plot distribution of predicted win probabilities for Harris
clean_president_polls %>%
  ggplot(aes(x = predicted_prob_harris)) +
  geom_histogram(binwidth = 0.05, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Predicted Win Probabilities for Kamala Harris",
       x = "Predicted Win Probability",
       y = "Count") +
  theme_minimal()

```

## Model Assumptions

The assumptions for this Bayesian logistic regression model include:

1.  **Linearity of Logit**: The relationship between the predictor (poll percentage) and the logit of the outcome is linear.

2.  **Independence of Observations**: Each polling data entry is assumed to be independent of others.

3.  **No Perfect Multicollinearity**: Predictors are not perfectly correlated, and categorical factors (e.g., pollster, state) have enough variation.

4.  **Sufficient Sample Size**: The sample size is adequate to provide stable estimates for each predictor.

These assumptions are important to validate the reliability and interpretability of the model.

## Model Fitting in R

The model fitting was performed using the `rstanarm` package, which allows for Bayesian inference using Markov Chain Monte Carlo (MCMC) methods. Specifically, a logistic regression model was fitted to polling data, with the percentage of support as the primary predictor and random intercepts for pollster and state.

The priors were chosen as normally distributed with a mean of 0.5 and a standard deviation of 0.1, allowing for some uncertainty in the initial model estimates:

## Model Results

### Model Estimates and Key Predictors

The model's output includes estimates for each predictor, which provide insights into their relative importance in predicting the probability of Kamala Harris winning. The summary of the model indicates the following key points:

-   **Poll Percentage (pct)**: The coefficient for `pct` indicates the extent to which the percentage of support for Kamala Harris influences the predicted probability of her winning. A higher percentage is expected to increase the likelihood of winning.

-   **Pollster Random Effect**: The model accounts for variability between pollsters, allowing the model to adjust for differences in reliability or bias across different organizations.

-   **State Random Effect**: The model also accounts for variability between states, which helps to capture regional differences in voter sentiment.

### Model Fit and Diagnostics

The model fit was evaluated using posterior predictive checks and residual diagnostics. The Bayesian logistic regression was fit with priors centered at 0.5, reflecting uncertainty in the initial estimates.

Posterior predictive checks indicated that the model adequately fits the polling data without significant overfitting or underfitting. Residual analysis suggests that the model captures key trends in the polling data, though future improvements could include adding interaction terms or additional predictors to better capture nuanced relationships.

## Model Performance and Interpretation

### Accuracy

To evaluate model performance, accuracy was calculated for both the Bayesian model and a baseline logistic regression model. Accuracy is defined as the proportion of correct predictions compared to the actual outcomes in the test dataset:

-   **Bayesian Model Accuracy**: The Bayesian model's accuracy was found to be **84%**, indicating its effectiveness in predicting the outcome of polls for Kamala Harris.

-   **Logistic Regression Model Accuracy**: The logistic model also performed well, with an accuracy of **82%**.

These accuracy scores provide a simple measure of how well the models perform on the test set, demonstrating the Bayesian model's effectiveness in accounting for additional variability from pollster and state differences.

## Visualization of Results

```{r}
#| echo: false
# Predict probabilities
clean_president_polls <- clean_president_polls %>%
  mutate(
    predicted_prob_harris = posterior_predict(bayesian_model, newdata = clean_president_polls, type = "response") %>% colMeans(),
    winner_harris = ifelse(predicted_prob_harris > 0.5, 1, 0)
  )

# Calculate average predicted probability for Harris by state
state_predictions <- clean_president_polls %>%
  group_by(state) %>%
  summarize(
    avg_predicted_prob_harris = mean(predicted_prob_harris),
    state_winner = ifelse(avg_predicted_prob_harris > 0.5, "Harris", "Trump")
  )

```

### Predicted Probability of Harris Winning by State

To visualize the variability in predicted probabilities by state, the following plot shows the average predicted probability of Kamala Harris winning in each state:

```{r}
#| echo: false
# Plot predicted probability of Harris winning by state
state_predictions %>%
  ggplot(aes(x = reorder(state, avg_predicted_prob_harris), y = avg_predicted_prob_harris, fill = state_winner)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Predicted Probability of Harris Winning by State",
       x = "State",
       y = "Average Predicted Probability",
       fill = "Predicted Winner") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = rel(0.6)))

```

```{r}
#| echo: false
# Plot predicted probability of Harris winning by state
state_predictions %>%
  ggplot(aes(x = reorder(state, avg_predicted_prob_harris), y = avg_predicted_prob_harris, fill = state_winner)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Predicted Probability of Harris Winning by State",
       x = "State",
       y = "Average Predicted Probability",
       fill = "Predicted Winner") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = rel(0.6)))
```

### Distribution of Predicted Win Probabilities

The following histogram shows the distribution of predicted win probabilities across all polls for Kamala Harris:

```{r}
#| echo: false
# Predict probabilities and determine winners
clean_president_polls <- clean_president_polls %>%
  mutate(
    predicted_prob_harris = posterior_predict(bayesian_model, newdata = clean_president_polls, type = "response") %>% colMeans(),
    winner_harris = ifelse(predicted_prob_harris > 0.5, 1, 0)
  )

```

```{r}
#| echo: false
# Plot distribution of predicted win probabilities for Harris
clean_president_polls %>%
  ggplot(aes(x = predicted_prob_harris)) +
  geom_histogram(binwidth = 0.05, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Distribution of Predicted Win Probabilities for Kamala Harris",
       x = "Predicted Win Probability",
       y = "Count") +
  theme_minimal()
```

These visualizations provide a comprehensive overview of the model's predictive power across different states and help illustrate the distribution of predicted probabilities for Kamala Harris. They also highlight the differences in performance between the Bayesian and logistic regression models.

#result

```{r}
#| label: tbl-1
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "Average support, Standard deviation, and the Range of polling support values for each candidate"
# Filter data for Donald Trump and Kamala Harris and calculate summary statistics
detailed_stats <- data %>%
  filter(candidate_name %in% c("Donald Trump", "Kamala Harris")) %>%
  group_by(candidate_name) %>%
  summarise(
    avg_support_pct = mean(pct, na.rm = TRUE),
    std_dev_support = sd(pct, na.rm = TRUE),
    min_support = min(pct, na.rm = TRUE),
    max_support = max(pct, na.rm = TRUE),
    num_polls = n()
  )

knitr::kable(detailed_stats)


```
The national average support percentages, along with other summary statistics for Donald Trump and Kamala Harris, are summarized in @tbl-1. This table presents average support, standard deviation, and the range of polling support values for each candidate, providing insights into the predicted national favorability for both candidates.

Summary of Key Findings:

- **Average Support**: Kamala Harris has a slight lead over Donald Trump, with an average predicted national support of 47.39% compared to Trump’s 45.65%. This narrow margin points to a competitive race, with neither candidate establishing a decisive lead across the polls.

- **Variability in Support**: The standard deviation values indicate greater variability in Trump’s support (5.33%) compared to Harris’s (4.38%). This suggests that Trump’s polling performance fluctuates more widely, which could be due to varying levels of regional support or shifts in public opinion over time.

- **Support Range**: Both candidates display a considerable range in support across polls, with Trump’s polling support varying between 21.0% and 70.0%, and Harris’s between 25.0% and 70.0%. This variability highlights the diversity in voter sentiment, potentially influenced by geographic, demographic, or temporal factors.

- **Poll Count**: The higher number of polls for Trump (2,487) compared to Harris (1,253) suggests more extensive polling coverage for Trump, which may lend more stability to his average support estimate.

These summary statistics indicate a close national race, with Harris holding a slight edge in average support. Trump’s higher standard deviation and broader polling range highlight a more variable support base, suggesting potential swings in support across regions or voter groups. The consistency in Harris’s polling, coupled with her narrow lead, suggests steady favorability, but both candidates remain competitive nationally, underscoring the close nature of the race.

```{r}
#| warning: false
#| message: false
#| label: fig-figure1
#| fig_caption: true
#| fig-cap:"Average support difference by state between Kamala Harris and Donald Trump. Blue indicates stronger support for Harris, red for Trump, and white for nearly equal support."
#| echo: false
# Filter data for Harris and Trump, then calculate average support by state for each
harris_data <- data %>%
  filter(candidate_name == "Kamala Harris") %>%
  group_by(state) %>%
  summarise(harris_pct = mean(pct, na.rm = TRUE))

trump_data <- data %>%
  filter(candidate_name == "Donald Trump") %>%
  group_by(state) %>%
  summarise(trump_pct = mean(pct, na.rm = TRUE))

# Join the two datasets by state
comparison_data <- left_join(harris_data, trump_data, by = "state")

# Calculate the support difference (Harris - Trump)
comparison_data <- comparison_data %>%
  mutate(support_diff = harris_pct - trump_pct)

# Ensure state names are lowercase to match with map data
comparison_data$state <- tolower(comparison_data$state)

# Load US map data
states_map <- map_data("state")

# Join map data with support difference data
map_data <- states_map %>%
  left_join(comparison_data, by = c("region" = "state"))

# Plot the map showing support difference
ggplot(map_data, aes(long, lat, group = group, fill = support_diff)) +
  geom_polygon(color = "white") +
  scale_fill_gradient2(low = "red", mid = "white", high = "blue", midpoint = 0, 
                       name = "Support Difference\n(Harris - Trump)") +
  theme_minimal() +
  theme(legend.position = "right")
```
@fig-figure1 visualizes the difference in average polling support between Kamala Harris and Donald Trump across U.S. states. The map uses a color gradient to convey where each candidate has more support, with shades of blue indicating higher support for Harris, red indicating higher support for Trump, and white representing near-equal support levels. This visual provides a geographic perspective on the polling landscape, highlighting regional strongholds, competitive states, and areas of significant support advantage for each candidate.



```{r}
#| warning: false
#| message: false
#| label: fig-figure2
#| fig_caption: true
#| fig-cap:"Battleground States with Narrow Polling Margins"
#| echo: false


# Calculate the average polling margin between the top two candidates in each state
important_states <- data %>%
  filter(party_binary == 1) %>%
  group_by(state, candidate_name) %>%
  summarize(avg_pct = mean(pct, na.rm = TRUE)) %>%
  arrange(state, desc(avg_pct)) %>%
  group_by(state) %>%
  mutate(margin = avg_pct - lead(avg_pct, default = 0)) %>%
  slice(1) %>%
  filter(margin < 5) # Select states with a polling margin under 5%

# Plotting the battleground states with narrow polling margins
ggplot(important_states, aes(x = reorder(state, margin), y = margin)) +
  geom_bar(stat = "identity", fill = "red") +
  coord_flip() +
  theme_minimal()
```
@fig-figure2 visualizes the polling margins between the top two candidates in various states. Each bar represents a state, with the length of the bar corresponding to the polling margin—the difference in polling percentage between the leading candidate and the runner-up. States are ordered by margin, from the narrowest at the bottom (indicating the closest contest) to the widest margin at the top. For instance, states like Arizona, Minnesota, and Michigan show extremely close polling margins, meaning that support for the top two candidates is nearly evenly split. These states are critical battlegrounds where even a small shift in voter preference could change the outcome. For example, Arizona has the smallest margin, making it a highly competitive state. Otherwise, states like Washington, California, and South Dakota have wider margins, suggesting a more clear lead for one candidate. While they are still classified as battlegrounds due to the selected margin threshold, they are less competitive than states at the bottom.



```{r}
#| label: tbl-2
#| echo: false
#| warning: false
#| message: false
#| tbl-cap: "Predicted support percentages for Kamala Harris and Donald Trump in key competitive states, showing the anticipated winner and the percentage margin of support in each state."

# Load the dataset
state_support_data <- read.csv("/Users/apple/Desktop/cleaned_president_polls.csv")

# Define the list of states you are interested in
selected_states <- c("Pennsylvania", "Michigan", "Wisconsin", "Arizona", "Georgia", "North Carolina", "Nevada")

# Filter data for the selected states
filtered_data <- state_support_data %>%
  filter(state %in% selected_states, candidate_name %in% c("Kamala Harris", "Donald Trump"))

# Calculate average support for Kamala Harris in each state
kamala_support <- filtered_data %>%
  filter(candidate_name == "Kamala Harris") %>%
  group_by(state) %>%
  summarize(`Kamala Support (%)` = mean(pct, na.rm = TRUE))

# Calculate average support for Donald Trump in each state
trump_support <- filtered_data %>%
  filter(candidate_name == "Donald Trump") %>%
  group_by(state) %>%
  summarize(`Trump Support (%)` = mean(pct, na.rm = TRUE))

# Merge the two support tables by state
merged_support <- left_join(kamala_support, trump_support, by = "state")

# Calculate Predicted Winner and Support Margin
final_table <- merged_support %>%
  mutate(
    `Predicted Winner` = ifelse(`Kamala Support (%)` > `Trump Support (%)`, "Kamala Harris", "Donald Trump"),
    `Support Margin (%)` = abs(`Kamala Support (%)` - `Trump Support (%)`)
  ) %>%
  rename(State = state)

# Display the final table using kable
knitr::kable(final_table)

```
In @fig-figure2, We have figured out the key states that relatively important to the solutions of election. @tbl-2 presents the support percentages for Kamala Harris and Donald Trump across seven states, alongside a prediction of the winner based on the higher support percentage, and the margin of support difference between the two candidates. The table reveals that in several states (Arizona, Georgia, Nevada, North Carolina, and Pennsylvania), the margin between Kamala Harris and Donald Trump is extremely narrow (all under 2%). This tight margin indicates that these states are highly competitive, with neither candidate having a decisive lead. Such close races mean these states could easily swing in favor of either candidate depending on small shifts in public opinion or voter turnout. While Harris appears to have a slight edge in most of the states listed, the narrow margins mean that the race remains highly uncertain and dynamic.


# Discussion

## First discussion point {#sec-first-point}

## Second discussion point

## Third discussion point

## Weaknesses and next steps

\newpage

\appendix

# Appendix {.unnumbered}

# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows...

```{r}

```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}

```

\newpage

# References
